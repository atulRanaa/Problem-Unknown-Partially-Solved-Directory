{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classification and encoding using WORD2VEC_Big.ipynb","version":"0.3.2","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"DEgtcC5-aKTg","colab_type":"code","outputId":"9f6a64c5-095d-4904-bf7e-a9c4b347046a","executionInfo":{"status":"ok","timestamp":1554979075251,"user_tz":-330,"elapsed":28004,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5PVjxKv5aS1t","colab_type":"code","outputId":"a0678e23-88d2-4aee-a2ca-a16206c5f22a","executionInfo":{"status":"ok","timestamp":1554979080349,"user_tz":-330,"elapsed":3173,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import pandas as pd\n","import numpy as np\n","import nltk\n","import re\n","from nltk.corpus import stopwords\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.preprocessing import normalize\n","from scipy.sparse import hstack\n","\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics.classification import accuracy_score, log_loss\n","from sklearn.model_selection import cross_val_predict\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.linear_model import LogisticRegression\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","import os\n","import gensim\n","nltk.download('punkt')\n","\n","from collections import defaultdict"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DtsVK_y2ThnF","colab_type":"text"},"source":["# Getting the Model"]},{"cell_type":"code","metadata":{"id":"b1l8AHGaafoy","colab_type":"code","colab":{}},"source":["model = gensim.models.Word2Vec.load('/content/gdrive/My Drive/w2vmodel_big')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUCaF3LKa71F","colab_type":"code","outputId":"6293f23a-60f7-4cb7-f64b-93682b4417c5","executionInfo":{"status":"ok","timestamp":1554979095952,"user_tz":-330,"elapsed":2048,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":245}},"source":["model.wv.most_similar('mutation')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["[('mutations', 0.7920259833335876),\n"," ('substitution', 0.6018621921539307),\n"," ('case', 0.5685200095176697),\n"," ('one', 0.551011323928833),\n"," ('alteration', 0.5437765121459961),\n"," ('found', 0.5348433256149292),\n"," ('cases', 0.5271749496459961),\n"," ('germline', 0.5236974954605103),\n"," ('somatic', 0.5220752954483032),\n"," ('patients', 0.5189864039421082)]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"6LiIdMpKXs_w","colab_type":"text"},"source":["### Vocab Size"]},{"cell_type":"code","metadata":{"id":"b7EpFGunbpdt","colab_type":"code","outputId":"169551ea-9303-4882-cb8f-397b1a0e64f7","executionInfo":{"status":"ok","timestamp":1554979098927,"user_tz":-330,"elapsed":1681,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["vocab = list(model.wv.vocab)\n","print(len(vocab))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["225844\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qs7sjnDvbOXo","colab_type":"code","outputId":"8209e02e-b0fb-4005-df3d-c1c1a217ece4","executionInfo":{"status":"ok","timestamp":1554979100811,"user_tz":-330,"elapsed":1076,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":364}},"source":["from itertools import islice\n","list(islice(vocab, 13030, 13050))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['d9e',\n"," 'gt239',\n"," 'genetex',\n"," 'bethyl',\n"," 'm2-coupled',\n"," 'horseradish-peroxidase-labeled',\n"," 'glo',\n"," 'x-tremegene',\n"," 'glutathione-coupled',\n"," 'taconic',\n"," 'labs',\n"," 'selleckchem',\n"," 'synthesized',\n"," 'hagst-s6k1',\n"," 'ha-gst-akt1',\n"," 'ha-gst-rheb1',\n"," 'flag-14-3-3',\n"," 'generous',\n"," 'yaffe',\n"," 'hek-293t-trex']"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"0nWD4hSKTl9x","colab_type":"text"},"source":["# Getting the Data"]},{"cell_type":"code","metadata":{"id":"1cW9P4UzgTJv","colab_type":"code","colab":{}},"source":["w2v_data = pd.read_csv('/content/gdrive/My Drive/w2v_data.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BGvW1_4vqSnm","colab_type":"code","outputId":"b9f4ec84-a794-48cd-f5c1-62d2a4cc5b62","executionInfo":{"status":"ok","timestamp":1554979115585,"user_tz":-330,"elapsed":1319,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["w2v_data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>fam58a truncating mutations cyclin-dependent k...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cbl w802* abstract background non-small cell l...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cbl q249e abstract background non-small cell l...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cbl n454d recent evidence demonstrated acquire...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cbl l399v oncogenic mutations monomeric casita...</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                Text  Class\n","0  fam58a truncating mutations cyclin-dependent k...      1\n","1  cbl w802* abstract background non-small cell l...      2\n","2  cbl q249e abstract background non-small cell l...      2\n","3  cbl n454d recent evidence demonstrated acquire...      3\n","4  cbl l399v oncogenic mutations monomeric casita...      4"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"-X4CWWhqqtdG","colab_type":"code","colab":{}},"source":["class TfidfEmbeddingVectorizer(object):\n","    def __init__(self, word2vec):\n","        self.word2vec = word2vec\n","        self.word2weight = None\n","        self.dim = len(word2vec.wv.syn0[0])\n","\n","    def fit(self, X):\n","        return self\n","\n","    def fit_transform(self, X):\n","        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n","        tfidf.fit(X)\n","        # if a word was never seen - it must be at least as infrequent\n","        # as any of the known words - so the default idf is the max of \n","        # known idf's\n","        max_idf = max(tfidf.idf_)\n","        self.word2weight = defaultdict(\n","            lambda: max_idf,\n","            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n","\n","        return np.array([\n","                np.mean([self.word2vec[w] * self.word2weight[w]\n","                         for w in words if w in self.word2vec] or\n","                        [np.zeros(self.dim)], axis=0)\n","                for words in X\n","            ])\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hqq2eJQXTp7S","colab_type":"text"},"source":["# Tokenizer and Embedding"]},{"cell_type":"markdown","metadata":{"id":"525mtXTQXxJ0","colab_type":"text"},"source":["### Tokenizer"]},{"cell_type":"code","metadata":{"id":"2Lkd3KVM2Xio","colab_type":"code","colab":{}},"source":["class MyTokenizer:\n","    def __init__(self):\n","        pass\n","    \n","    def fit(self, X, y=None):\n","        return self\n","    \n","    def transform(self, X):\n","        transformed_X = []\n","        for document in X:\n","            tokenized_doc = []\n","            for sent in nltk.sent_tokenize(document):\n","                tokenized_doc += nltk.word_tokenize(sent)\n","            transformed_X.append(np.array(tokenized_doc))\n","        return np.array(transformed_X)\n","    \n","    def fit_transform(self, X, y=None):\n","        return self.transform(X)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b0J3YSBfX0CR","colab_type":"text"},"source":["### Embedding"]},{"cell_type":"code","metadata":{"id":"Wa0z4NJ62aCh","colab_type":"code","colab":{}},"source":["class MeanEmbeddingVectorizer(object):\n","    def __init__(self, word2vec):\n","        self.word2vec = word2vec\n","        # if a text is empty we should return a vector of zeros\n","        # with the same dimensionality as all the other vectors\n","        self.dim = len(word2vec.wv.syn0[0])\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        X = MyTokenizer().fit_transform(X)\n","        \n","        return np.array([\n","            np.mean([self.word2vec.wv[w] for w in words if w in self.word2vec.wv]\n","                    or [np.zeros(self.dim)], axis=0)\n","            for words in X\n","        ])\n","    \n","    def fit_transform(self, X, y=None):\n","        return self.transform(X)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fYzxdBgw2dq6","colab_type":"code","outputId":"f0eb109e-c557-417f-b953-7e8b4fbc02e0","executionInfo":{"status":"ok","timestamp":1554979348407,"user_tz":-330,"elapsed":214556,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["mean_embedding_vectorizer = MeanEmbeddingVectorizer(model)\n","mean_embedded = mean_embedding_vectorizer.fit_transform(w2v_data['Text'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"tVHz1zUB_vjQ","colab_type":"code","colab":{}},"source":["from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.naive_bayes import ComplementNB\n","from sklearn.linear_model import SGDClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i6ABbnngAAfJ","colab_type":"code","outputId":"a9b82d55-284a-4d37-cea9-a73251543c66","executionInfo":{"status":"ok","timestamp":1554979604160,"user_tz":-330,"elapsed":1903,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["type(mean_embedded)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"yh7kFD9IAb6V","colab_type":"code","outputId":"9e3af9de-f088-4902-be87-de8e30baa0ed","executionInfo":{"status":"ok","timestamp":1554979620999,"user_tz":-330,"elapsed":1333,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["mean_embedded.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3321, 300)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"34vQQxBAAgKL","colab_type":"code","outputId":"ac51324e-e69f-48ad-deac-6362367680a0","executionInfo":{"status":"ok","timestamp":1554979640602,"user_tz":-330,"elapsed":1333,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":885}},"source":["print(mean_embedded[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[-0.33483508 -0.4234247   0.1903168  -0.07608256  0.50291115  0.07554512\n","  0.15030444 -0.01006396 -0.13573194  0.15463531 -0.231468    0.23079197\n"," -0.03590651 -0.02440811 -0.07382004  0.07969389  0.03842213  0.13287629\n","  0.28766048  0.06228872  0.15174717 -0.05815761  0.28997976 -0.43329698\n"," -0.1056528  -0.09698886 -0.2733862  -0.05692174 -0.00884036 -0.19348675\n","  0.2821662   0.19719823 -0.24916247  0.04985579 -0.6404954   0.0165292\n"," -0.57253087  0.06189586  0.04557919  0.07512408 -0.01794662  0.28100377\n","  0.20604512 -0.11275636  0.5672029  -0.14782198  0.26388898 -0.3960545\n","  0.23061322 -0.514577   -0.06700831  0.21000037 -0.06305815 -0.23955007\n","  0.35592777 -0.17854221 -0.195387    0.07227565  0.0394758  -0.10733049\n"," -0.15965869 -0.29026085 -0.46385333 -0.25229338  0.06003476 -0.18649456\n","  0.06582275 -0.08651158 -0.3130542  -0.23331259  0.0225482   0.057657\n","  0.1660362   0.02748245 -0.36863202  0.31750703  0.24861993  0.61338115\n"," -0.09689697  0.759378    0.15205783 -0.01211227  0.18304183  0.35556075\n"," -0.28162184  0.01962814 -0.564914   -0.24428226 -0.16062681  0.28169605\n"," -0.40596703 -0.19924997 -0.01717417  0.04101759  0.15585938  0.00386198\n"," -0.15745234 -0.20460382 -0.04605005  0.14788309  0.06132591 -0.05609436\n"," -0.3463878  -0.07494739  0.00605555  0.21746407  0.21005759  0.0784149\n"," -0.3167362  -0.01387357  0.11440118  0.14862724 -0.06025766  0.15391868\n"," -0.04223173  0.28941333 -0.21018393  0.30744055 -0.24589449  0.05347375\n","  0.12144734 -0.20863637  0.22871098 -0.01949452  0.02614903 -0.22810197\n"," -0.00916628 -0.4892481   0.09749311 -0.26562393 -0.0941427   0.23409495\n","  0.28367832  0.10829848  0.3419573  -0.19016619  0.20334922  0.4932895\n"," -0.33205107  0.10075472  0.07681985  0.09474535  0.13692454  0.22264205\n"," -0.33623114 -0.21123458  0.24186844  0.09531742  0.1818698  -0.28113157\n"," -0.03132218  0.04143315 -0.22219586  0.29435083  0.39940977 -0.394274\n","  0.09171755  0.04744045 -0.20894246  0.17232148 -0.04686307  0.02864162\n","  0.14892893 -0.23589532  0.04036301  0.3627508  -0.12908936 -0.4217752\n","  0.6439129   0.13692002  0.1210169  -0.01307147 -0.09934796  0.16845533\n"," -0.01106778  0.1387912   0.10482576  0.30656555  0.26128674  0.10408607\n","  0.17654969  0.23669603 -0.10093539  0.33044484 -0.21036297  0.03641564\n","  0.12499181 -0.07645686  0.18418196 -0.12881961  0.23361248  0.32177496\n"," -0.26334107  0.00891425  0.17213985  0.11893079 -0.10198154  0.11796302\n","  0.08799088  0.00725785 -0.07957389  0.02393812  0.21932158  0.5510863\n"," -0.29808617  0.11490766  0.18302034 -0.01701301  0.3034602   0.39757589\n"," -0.06719563 -0.68215144  0.4284231   0.0399386  -0.06580875 -0.06353817\n"," -0.00248772 -0.17434534  0.24645329  0.31050342  0.12456542 -0.0778326\n"," -0.10447961  0.03619699 -0.02792681 -0.11180779 -0.16434142  0.18897486\n"," -0.01408552  0.2972377  -0.25370792  0.02237615 -0.01095394  0.5807791\n","  0.21854089  0.28879428 -0.05761337 -0.48797187  0.30966425  0.23338915\n"," -0.05731601  0.62963504  0.08717778 -0.54190767 -0.26092306  0.03077972\n","  0.26770952  0.10056493  0.30049834  0.59231555 -0.44052646  0.20493898\n","  0.20230909  0.1291972  -0.11772609  0.4012123   0.3681493   0.12503202\n","  0.0529489  -0.13971558  0.25838712  0.10923544 -0.14575836 -0.3176037\n"," -0.10663325 -0.49300164  0.34836188 -0.03495238  0.04273255  0.45745155\n"," -0.14306508 -0.03946272  0.08071878 -0.25701496 -0.19654477 -0.12547265\n"," -0.14784609  0.04504455  0.6119323  -0.06541906 -0.08708986 -0.05684478\n"," -0.10426665 -0.01932134  0.07680438  0.23039263  0.6872403   0.24634145\n","  0.2094529  -0.03687527 -0.27198315 -0.39131656  0.32777515  0.08953163\n"," -0.59090483  0.00096541  0.06409427 -0.20594335 -0.13269852 -0.28020757]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0eBOutynUCr1","colab_type":"text"},"source":["# Prediction Function"]},{"cell_type":"code","metadata":{"id":"UWB9YTFrD28M","colab_type":"code","colab":{}},"source":["def predict_and_plot_confusion_matrix(X, Y, clf):\n","    train_x, test_x, train_y, test_y = train_test_split(X, Y, stratify= Y , test_size=0.2)\n","    \n","    \n","    \n","    clf.fit(train_x, train_y)\n","    \n","    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n","    sig_clf.fit(train_x, train_y)\n","    pred_y = sig_clf.predict(test_x)\n","\n","    # for calculating log_loss we will provide the array of probabilities belongs to each class\n","    print(\"Log loss :\",log_loss(test_y, sig_clf.predict_proba(test_x)))\n","    print(\"Actual :\", test_y[0])\n","    print(\"Probability :\",np.round(sig_clf.predict_proba(test_x[0].reshape(1, -1) ),4 ))\n","    print(\"Predicted :\", sig_clf.predict(test_x[0].reshape(1, -1) ))\n","    # calculating the number of data points that are misclassified\n","    # print(\"Number of mis-classified points :\", np.count_nonzero((pred_y- test_y))/test_y.shape[0], 1-np.count_nonzero((pred_y- test_y))/test_y.shape[0])\n","    print(confusion_matrix(test_y, pred_y))\n","    print(\"Score :\",sig_clf.score(test_x, test_y))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p_2sI1mGT87p","colab_type":"text"},"source":["# Normalization of Encoded Vectors"]},{"cell_type":"code","metadata":{"id":"9yslPSQuuoQn","colab_type":"code","colab":{}},"source":["mean_embedded  = normalize(mean_embedded, axis = 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dd_kuIUhwFS9","colab_type":"code","outputId":"a7ed021b-539c-4e79-99d0-b618fdcbcdf9","executionInfo":{"status":"ok","timestamp":1554992442784,"user_tz":-330,"elapsed":1899,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["min_val = min( [ min(vec) for vec in mean_embedded] )\n","print(min_val)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["-0.29168472\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nj7RjmIyxdup","colab_type":"code","outputId":"b805d5fc-b3b9-4c15-acd6-685d4f1cfdac","executionInfo":{"status":"ok","timestamp":1554992630436,"user_tz":-330,"elapsed":2248,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x, y  = mean_embedded.shape\n","print(x,y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3321 300\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AdCA5NnFyJmE","colab_type":"code","colab":{}},"source":["for i in range(x):\n","  for j in range(y):\n","    mean_embedded[i][j] += abs(min_val)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"THVrAjqbyYJd","colab_type":"code","outputId":"5b95110f-1813-4b39-d4f1-9bb36b8c90c4","executionInfo":{"status":"ok","timestamp":1554992710143,"user_tz":-330,"elapsed":2288,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["min( [ min(vec) for vec in mean_embedded] )"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"AxB_nPGDzg1L","colab_type":"code","colab":{}},"source":["mean_embedded = np.array( mean_embedded )\n","y = np.array( list( w2v_data['Class'].values ) )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"agBUDmjJz8ID","colab_type":"code","outputId":"4625b504-e82e-4f27-ab98-39d38f068804","executionInfo":{"status":"ok","timestamp":1554993492133,"user_tz":-330,"elapsed":2510,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","y.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3321,)"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"porx1vQf1uzu","colab_type":"code","outputId":"81053a71-5e38-44c8-abd0-731ef8e2a810","executionInfo":{"status":"ok","timestamp":1554993584480,"user_tz":-330,"elapsed":1542,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["mean_embedded.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3321, 300)"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"Z2HYKOOa1bZY","colab_type":"code","outputId":"89334316-4ac4-4456-f189-e7a62646491c","executionInfo":{"status":"ok","timestamp":1554993595935,"user_tz":-330,"elapsed":1799,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["mean_embedded[0].reshape(1, -1).shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 300)"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"markdown","metadata":{"id":"LcJ3KZ16UJ_Z","colab_type":"text"},"source":["# Classification"]},{"cell_type":"markdown","metadata":{"id":"HLyDPDnYUMmk","colab_type":"text"},"source":["## Naive Bayes"]},{"cell_type":"code","metadata":{"id":"QhxGlx5yefNE","colab_type":"code","outputId":"2a4afc15-57ae-4382-a293-5d5b6e0a125e","executionInfo":{"status":"ok","timestamp":1554993652095,"user_tz":-330,"elapsed":1893,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":315}},"source":["predict_and_plot_confusion_matrix(mean_embedded, y,\n","                                 MultinomialNB()\n","                                 )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n","  warnings.warn(CV_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Log loss : 1.4050483613028375\n","Actual : 5\n","Probability : [[0.329  0.0301 0.0293 0.3586 0.1126 0.1021 0.0337 0.0037 0.0009]]\n","Predicted : [4]\n","[[ 42  13   0  43   0   2  14   0   0]\n"," [  8  25   0   5   0   0  53   0   0]\n"," [  1   1   0   8   0   0   8   0   0]\n"," [ 31   5   0  70   0   3  28   0   0]\n"," [ 15   2   0   7  10   3  11   0   0]\n"," [  4   3   0  12   0  15  21   0   0]\n"," [  4  16   0  10   0   0 161   0   0]\n"," [  3   0   0   0   0   0   1   0   0]\n"," [  3   0   0   1   0   0   0   0   3]]\n","Score : 0.49022556390977445\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wLsd2ktNUUOj","colab_type":"text"},"source":["## XGBoost"]},{"cell_type":"code","metadata":{"id":"dKn2FsBafaSS","colab_type":"code","outputId":"69e45ea8-7073-4142-b324-a2e6ce8f8d57","executionInfo":{"status":"ok","timestamp":1554993961570,"user_tz":-330,"elapsed":211165,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":662}},"source":["predict_and_plot_confusion_matrix(mean_embedded, y,\n","                                  XGBClassifier(max_depth=4,\n","                                      objective='multi:softprob',\n","                                      learning_rate=0.03333,\n","                                      )\n","                                 )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n","  warnings.warn(CV_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:447: RuntimeWarning: divide by zero encountered in log\n","  l = -(T * np.log(P + tiny) + T1 * np.log(1. - P + tiny))\n","/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:447: RuntimeWarning: divide by zero encountered in log\n","  l = -(T * np.log(P + tiny) + T1 * np.log(1. - P + tiny))\n","/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:447: RuntimeWarning: divide by zero encountered in log\n","  l = -(T * np.log(P + tiny) + T1 * np.log(1. - P + tiny))\n","/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:447: RuntimeWarning: divide by zero encountered in log\n","  l = -(T * np.log(P + tiny) + T1 * np.log(1. - P + tiny))\n","/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:447: RuntimeWarning: divide by zero encountered in log\n","  l = -(T * np.log(P + tiny) + T1 * np.log(1. - P + tiny))\n","/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:447: RuntimeWarning: divide by zero encountered in log\n","  l = -(T * np.log(P + tiny) + T1 * np.log(1. - P + tiny))\n","/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:447: RuntimeWarning: divide by zero encountered in log\n","  l = -(T * np.log(P + tiny) + T1 * np.log(1. - P + tiny))\n","/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:447: RuntimeWarning: divide by zero encountered in log\n","  l = -(T * np.log(P + tiny) + T1 * np.log(1. - P + tiny))\n","/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:447: RuntimeWarning: divide by zero encountered in log\n","  l = -(T * np.log(P + tiny) + T1 * np.log(1. - P + tiny))\n","/usr/local/lib/python3.6/dist-packages/sklearn/calibration.py:447: RuntimeWarning: divide by zero encountered in log\n","  l = -(T * np.log(P + tiny) + T1 * np.log(1. - P + tiny))\n"],"name":"stderr"},{"output_type":"stream","text":["Log loss : 1.1139643611411982\n","Actual : 2\n","Probability : [[0.0881 0.3649 0.0209 0.0509 0.0421 0.0388 0.3803 0.0067 0.0073]]\n","Predicted : [7]\n","[[ 74   2   0  22   4   2   9   0   1]\n"," [  5  42   0   0   0   0  44   0   0]\n"," [  3   0   2   6   1   0   6   0   0]\n"," [ 26   4   0  84   4   0  19   0   0]\n"," [ 14   4   0   5  13   4   8   0   0]\n"," [ 10   1   0   3   3  30   8   0   0]\n"," [  3  22   1   5   1   0 159   0   0]\n"," [  2   1   0   0   0   0   1   0   0]\n"," [  1   0   0   0   0   0   1   1   4]]\n","Score : 0.6135338345864662\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"44oAMF64UX43","colab_type":"text"},"source":["## Logistic Regression"]},{"cell_type":"code","metadata":{"id":"JRx1Ofk22aDC","colab_type":"code","outputId":"06f491fe-d11e-42b0-be93-77b52c4b3f9b","executionInfo":{"status":"ok","timestamp":1554994066399,"user_tz":-330,"elapsed":6149,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":315}},"source":["predict_and_plot_confusion_matrix(mean_embedded, y,\n","                                  SGDClassifier(class_weight='balanced', alpha=0.001, penalty='l2', loss='log', random_state=32 ,max_iter=1000, tol=0.0001)\n","                                 )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n","  warnings.warn(CV_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Log loss : 1.342423864672542\n","Actual : 2\n","Probability : [[0.0591 0.2123 0.0315 0.1036 0.0482 0.0512 0.4884 0.0048 0.0008]]\n","Predicted : [7]\n","[[ 54   9   0  32   1   6  12   0   0]\n"," [  3  24   0   6   0   0  56   0   2]\n"," [  0   1   0   5   1   0  11   0   0]\n"," [ 31   5   0  85   0   0  16   0   0]\n"," [ 12   0   0  10  10   5  11   0   0]\n"," [ 11   2   0   7   1  19  15   0   0]\n"," [  2  19   0  10   0   0 160   0   0]\n"," [  1   0   0   0   0   0   3   0   0]\n"," [  0   1   0   3   0   0   1   0   2]]\n","Score : 0.5323308270676692\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rd8Oo5eiUfUV","colab_type":"text"},"source":["## Random Forest"]},{"cell_type":"code","metadata":{"id":"AZWeeBBx4AmX","colab_type":"code","outputId":"20b0b228-fc46-4e9f-8eb9-8d3e11c52ad9","executionInfo":{"status":"ok","timestamp":1554994337524,"user_tz":-330,"elapsed":105061,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":315}},"source":["from sklearn.ensemble import RandomForestClassifier\n","clf = RandomForestClassifier(n_estimators=1000, oob_score=True)\n","predict_and_plot_confusion_matrix(mean_embedded, y, clf)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n","  warnings.warn(CV_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Log loss : 1.052296765627609\n","Actual : 1\n","Probability : [[0.4246 0.1875 0.0156 0.142  0.0494 0.0375 0.1285 0.0082 0.0067]]\n","Predicted : [1]\n","[[ 65   1   1  29   4   1  13   0   0]\n"," [  3  46   0   2   1   1  38   0   0]\n"," [  1   0   8   1   0   0   8   0   0]\n"," [ 14   4   2 108   0   0   9   0   0]\n"," [ 14   1   1   8  14   1   9   0   0]\n"," [  8   2   0   2   1  29  13   0   0]\n"," [  2  19   1   4   1   0 164   0   0]\n"," [  2   0   0   1   0   0   1   0   0]\n"," [  2   0   0   0   0   0   1   0   4]]\n","Score : 0.6586466165413534\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pj4RuxhoVk1-","colab_type":"text"},"source":["## SVC"]},{"cell_type":"code","metadata":{"id":"8dvAMDQj4JPB","colab_type":"code","outputId":"729b0aa3-66ba-4dd6-cd5e-22da752beeee","executionInfo":{"status":"ok","timestamp":1554994399609,"user_tz":-330,"elapsed":5564,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":315}},"source":["clf = SGDClassifier(alpha=0.001, penalty='l2', loss='hinge', random_state=123 ,max_iter=10000, tol=0.00001)\n","predict_and_plot_confusion_matrix(mean_embedded, y, clf)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n","  warnings.warn(CV_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Log loss : 1.2724323439779115\n","Actual : 4\n","Probability : [[0.0547 0.1543 0.0209 0.2002 0.0388 0.0457 0.4816 0.0025 0.0013]]\n","Predicted : [7]\n","[[ 65   3   0  28   6   6   6   0   0]\n"," [  9  23   0   3   0   1  55   0   0]\n"," [  1   0   0   6   1   0  10   0   0]\n"," [ 32   1   0  76   7   2  19   0   0]\n"," [  8   2   0   6  18   2  12   0   0]\n"," [ 10   0   0   4   2  20  19   0   0]\n"," [ 12  22   0  11   0   1 145   0   0]\n"," [  0   0   0   1   0   0   2   0   1]\n"," [  1   0   0   2   0   0   2   0   2]]\n","Score : 0.524812030075188\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L763nyqvUu3z","colab_type":"text"},"source":["## Perceptron"]},{"cell_type":"code","metadata":{"id":"wmVmvm6I43L2","colab_type":"code","outputId":"57359f33-b299-4506-bf17-12e1eceb3294","executionInfo":{"status":"ok","timestamp":1554994430962,"user_tz":-330,"elapsed":2395,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":315}},"source":["from sklearn.linear_model import Perceptron\n","clf = Perceptron(max_iter=10000, tol=0.00001)\n","predict_and_plot_confusion_matrix(mean_embedded, y, clf)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n","  warnings.warn(CV_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Log loss : 1.2978257211115216\n","Actual : 1\n","Probability : [[0.0925 0.0865 0.029  0.0853 0.1162 0.1096 0.4743 0.0054 0.0012]]\n","Predicted : [7]\n","[[ 42   0   0  50   2   7  12   0   1]\n"," [  7  15   0   2   1   2  64   0   0]\n"," [  3   0   0   4   2   0   9   0   0]\n"," [ 21   1   0  85   4   3  23   0   0]\n"," [ 12   1   0   7   6   5  17   0   0]\n"," [  6   1   0   6   4  22  16   0   0]\n"," [  6   3   0  14   0   0 168   0   0]\n"," [  1   0   0   2   0   0   1   0   0]\n"," [  0   0   0   2   0   0   1   0   4]]\n","Score : 0.5142857142857142\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VjHyMcUHUw_3","colab_type":"text"},"source":["## Support Vector Classifier"]},{"cell_type":"code","metadata":{"id":"RM0tGOnO4_nF","colab_type":"code","outputId":"57abaa89-9b9c-4de9-8b21-93da2d8142bf","executionInfo":{"status":"ok","timestamp":1554994539703,"user_tz":-330,"elapsed":12782,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":332}},"source":["from sklearn.svm import SVC\n","clf =  SVC(kernel=\"linear\", C=1)\n","predict_and_plot_confusion_matrix(mean_embedded, y, clf)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n","  warnings.warn(CV_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Log loss : 1.9451888796706978\n","Actual : 4\n","Probability : [[3.154e-01 2.380e-02 2.000e-04 5.012e-01 5.580e-02 8.130e-02 2.230e-02\n","  0.000e+00 0.000e+00]]\n","Predicted : [4]\n","[[ 31   0   0  53   0   3  21   4   2]\n"," [  1   0   0   3   0   0  85   2   0]\n"," [  1   0   0   7   0   0  10   0   0]\n"," [ 18   0   0  82   0   4  29   4   0]\n"," [ 10   0   0  16   0   4  14   4   0]\n"," [  8   0   0  16   0  12  19   0   0]\n"," [  1   0   0   7   0   0 179   3   1]\n"," [  1   0   0   1   0   0   2   0   0]\n"," [  1   0   0   3   0   0   0   0   3]]\n","Score : 0.4616541353383459\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f7PWbN-QU1EF","colab_type":"text"},"source":["## MLP Classifier ANN"]},{"cell_type":"code","metadata":{"id":"4C2qHVIo76kh","colab_type":"code","outputId":"feab77c1-6ae8-4206-fde5-1c71314fc900","executionInfo":{"status":"ok","timestamp":1554995574884,"user_tz":-330,"elapsed":149010,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":10283}},"source":["clf = MLPClassifier(hidden_layer_sizes=(500,300,100), max_iter=1000, alpha=0.0001,solver='adam', verbose=10,  random_state=21, tol=0.000000001)\n","predict_and_plot_confusion_matrix(mean_embedded, y, clf)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Iteration 1, loss = 1.91939032\n","Iteration 2, loss = 1.84416537\n","Iteration 3, loss = 1.83593800\n","Iteration 4, loss = 1.83324555\n","Iteration 5, loss = 1.83354310\n","Iteration 6, loss = 1.82965069\n","Iteration 7, loss = 1.82777794\n","Iteration 8, loss = 1.82782871\n","Iteration 9, loss = 1.83082607\n","Iteration 10, loss = 1.81809141\n","Iteration 11, loss = 1.79468963\n","Iteration 12, loss = 1.84032221\n","Iteration 13, loss = 1.80641061\n","Iteration 14, loss = 1.78630206\n","Iteration 15, loss = 1.75900094\n","Iteration 16, loss = 1.71871381\n","Iteration 17, loss = 1.69393742\n","Iteration 18, loss = 1.63372993\n","Iteration 19, loss = 1.65303152\n","Iteration 20, loss = 1.62196200\n","Iteration 21, loss = 1.57473978\n","Iteration 22, loss = 1.59362802\n","Iteration 23, loss = 1.56938077\n","Iteration 24, loss = 1.58983416\n","Iteration 25, loss = 1.58046589\n","Iteration 26, loss = 1.58196848\n","Iteration 27, loss = 1.54165900\n","Iteration 28, loss = 1.58183448\n","Iteration 29, loss = 1.51948454\n","Iteration 30, loss = 1.52763779\n","Iteration 31, loss = 1.51273574\n","Iteration 32, loss = 1.57118094\n","Iteration 33, loss = 1.53310550\n","Iteration 34, loss = 1.52762369\n","Iteration 35, loss = 1.49991759\n","Iteration 36, loss = 1.49790182\n","Iteration 37, loss = 1.47910906\n","Iteration 38, loss = 1.52927324\n","Iteration 39, loss = 1.48514965\n","Iteration 40, loss = 1.49734007\n","Iteration 41, loss = 1.49128990\n","Iteration 42, loss = 1.46470261\n","Iteration 43, loss = 1.47106927\n","Iteration 44, loss = 1.48014769\n","Iteration 45, loss = 1.47601175\n","Iteration 46, loss = 1.47312004\n","Iteration 47, loss = 1.51735096\n","Iteration 48, loss = 1.44196288\n","Iteration 49, loss = 1.47436576\n","Iteration 50, loss = 1.44088723\n","Iteration 51, loss = 1.43368978\n","Iteration 52, loss = 1.45172042\n","Iteration 53, loss = 1.45000997\n","Iteration 54, loss = 1.45888320\n","Iteration 55, loss = 1.48740728\n","Iteration 56, loss = 1.43758114\n","Iteration 57, loss = 1.44391988\n","Iteration 58, loss = 1.46301227\n","Iteration 59, loss = 1.42787382\n","Iteration 60, loss = 1.40955773\n","Iteration 61, loss = 1.42642442\n","Iteration 62, loss = 1.44855832\n","Iteration 63, loss = 1.42430344\n","Iteration 64, loss = 1.41272729\n","Iteration 65, loss = 1.46592784\n","Iteration 66, loss = 1.42860148\n","Iteration 67, loss = 1.43788860\n","Iteration 68, loss = 1.43534769\n","Iteration 69, loss = 1.47272463\n","Iteration 70, loss = 1.42903419\n","Iteration 71, loss = 1.39182908\n","Iteration 72, loss = 1.39258391\n","Iteration 73, loss = 1.42037584\n","Iteration 74, loss = 1.43670547\n","Iteration 75, loss = 1.39551315\n","Iteration 76, loss = 1.46113923\n","Iteration 77, loss = 1.47286269\n","Iteration 78, loss = 1.44436780\n","Iteration 79, loss = 1.41922592\n","Iteration 80, loss = 1.40380364\n","Iteration 81, loss = 1.40256573\n","Iteration 82, loss = 1.37780121\n","Iteration 83, loss = 1.37217019\n","Iteration 84, loss = 1.37119178\n","Iteration 85, loss = 1.39556155\n","Iteration 86, loss = 1.37670757\n","Iteration 87, loss = 1.37590947\n","Iteration 88, loss = 1.37733922\n","Iteration 89, loss = 1.36397787\n","Iteration 90, loss = 1.39286208\n","Iteration 91, loss = 1.37219486\n","Iteration 92, loss = 1.37583982\n","Iteration 93, loss = 1.39493387\n","Iteration 94, loss = 1.36864270\n","Iteration 95, loss = 1.35505129\n","Iteration 96, loss = 1.37031763\n","Iteration 97, loss = 1.37583872\n","Iteration 98, loss = 1.39675593\n","Iteration 99, loss = 1.42634681\n","Iteration 100, loss = 1.36390885\n","Iteration 101, loss = 1.36476255\n","Iteration 102, loss = 1.34087049\n","Iteration 103, loss = 1.33437163\n","Iteration 104, loss = 1.33470949\n","Iteration 105, loss = 1.35654755\n","Iteration 106, loss = 1.35123042\n","Iteration 107, loss = 1.36314933\n","Iteration 108, loss = 1.33099770\n","Iteration 109, loss = 1.33010130\n","Iteration 110, loss = 1.33759461\n","Iteration 111, loss = 1.33585520\n","Iteration 112, loss = 1.37296591\n","Iteration 113, loss = 1.40094626\n","Iteration 114, loss = 1.40959051\n","Iteration 115, loss = 1.37173091\n","Iteration 116, loss = 1.36587980\n","Iteration 117, loss = 1.39122687\n","Iteration 118, loss = 1.33923804\n","Iteration 119, loss = 1.32584252\n","Iteration 120, loss = 1.34124442\n","Iteration 121, loss = 1.33658605\n","Iteration 122, loss = 1.33872237\n","Iteration 123, loss = 1.38390934\n","Iteration 124, loss = 1.33103955\n","Iteration 125, loss = 1.43005531\n","Iteration 126, loss = 1.37957472\n","Iteration 127, loss = 1.32040385\n","Iteration 128, loss = 1.34969271\n","Iteration 129, loss = 1.36744705\n","Iteration 130, loss = 1.35173645\n","Iteration 131, loss = 1.33160564\n","Iteration 132, loss = 1.31774709\n","Iteration 133, loss = 1.30875900\n","Iteration 134, loss = 1.32953716\n","Iteration 135, loss = 1.31157400\n","Iteration 136, loss = 1.30316223\n","Iteration 137, loss = 1.34521169\n","Iteration 138, loss = 1.35018933\n","Iteration 139, loss = 1.38418289\n","Iteration 140, loss = 1.33529533\n","Iteration 141, loss = 1.31963027\n","Iteration 142, loss = 1.30397436\n","Iteration 143, loss = 1.29783414\n","Iteration 144, loss = 1.33481608\n","Iteration 145, loss = 1.37039067\n","Iteration 146, loss = 1.39017608\n","Iteration 147, loss = 1.34210709\n","Iteration 148, loss = 1.29539904\n","Iteration 149, loss = 1.31443211\n","Iteration 150, loss = 1.30286897\n","Iteration 151, loss = 1.29512905\n","Iteration 152, loss = 1.33761900\n","Iteration 153, loss = 1.34694920\n","Iteration 154, loss = 1.30605410\n","Iteration 155, loss = 1.28654622\n","Iteration 156, loss = 1.28069524\n","Iteration 157, loss = 1.30156986\n","Iteration 158, loss = 1.35606997\n","Iteration 159, loss = 1.30813014\n","Iteration 160, loss = 1.28390873\n","Iteration 161, loss = 1.31764634\n","Iteration 162, loss = 1.34863329\n","Iteration 163, loss = 1.35368702\n","Iteration 164, loss = 1.32253838\n","Iteration 165, loss = 1.27599151\n","Iteration 166, loss = 1.28810661\n","Iteration 167, loss = 1.27325425\n","Iteration 168, loss = 1.27607144\n","Iteration 169, loss = 1.29483654\n","Iteration 170, loss = 1.29574447\n","Iteration 171, loss = 1.28522778\n","Iteration 172, loss = 1.26044279\n","Iteration 173, loss = 1.27859479\n","Iteration 174, loss = 1.27239814\n","Iteration 175, loss = 1.26066268\n","Iteration 176, loss = 1.26962364\n","Iteration 177, loss = 1.29957435\n","Iteration 178, loss = 1.28868248\n","Iteration 179, loss = 1.28779376\n","Iteration 180, loss = 1.28675264\n","Iteration 181, loss = 1.26977851\n","Iteration 182, loss = 1.28779513\n","Iteration 183, loss = 1.25249937\n","Iteration 184, loss = 1.29846497\n","Iteration 185, loss = 1.32561785\n","Iteration 186, loss = 1.29188843\n","Iteration 187, loss = 1.26885522\n","Iteration 188, loss = 1.30461492\n","Iteration 189, loss = 1.27943111\n","Iteration 190, loss = 1.27066868\n","Iteration 191, loss = 1.30855307\n","Iteration 192, loss = 1.28601259\n","Iteration 193, loss = 1.29037449\n","Iteration 194, loss = 1.30020012\n","Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n","  warnings.warn(CV_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Iteration 1, loss = 1.96298350\n","Iteration 2, loss = 1.84515582\n","Iteration 3, loss = 1.84249095\n","Iteration 4, loss = 1.84171607\n","Iteration 5, loss = 1.83422421\n","Iteration 6, loss = 1.83435220\n","Iteration 7, loss = 1.83309429\n","Iteration 8, loss = 1.83197836\n","Iteration 9, loss = 1.84124827\n","Iteration 10, loss = 1.83070305\n","Iteration 11, loss = 1.83191197\n","Iteration 12, loss = 1.82586493\n","Iteration 13, loss = 1.82893655\n","Iteration 14, loss = 1.82535115\n","Iteration 15, loss = 1.82139229\n","Iteration 16, loss = 1.81681753\n","Iteration 17, loss = 1.81348841\n","Iteration 18, loss = 1.80149121\n","Iteration 19, loss = 1.79481927\n","Iteration 20, loss = 1.79950636\n","Iteration 21, loss = 1.79259800\n","Iteration 22, loss = 1.77923365\n","Iteration 23, loss = 1.77082636\n","Iteration 24, loss = 1.77149498\n","Iteration 25, loss = 1.81425608\n","Iteration 26, loss = 1.77815067\n","Iteration 27, loss = 1.72635600\n","Iteration 28, loss = 1.70472545\n","Iteration 29, loss = 1.67900451\n","Iteration 30, loss = 1.65356829\n","Iteration 31, loss = 1.68108129\n","Iteration 32, loss = 1.66993773\n","Iteration 33, loss = 1.62172299\n","Iteration 34, loss = 1.60290717\n","Iteration 35, loss = 1.57168251\n","Iteration 36, loss = 1.57151314\n","Iteration 37, loss = 1.55919957\n","Iteration 38, loss = 1.54985349\n","Iteration 39, loss = 1.56508184\n","Iteration 40, loss = 1.52937888\n","Iteration 41, loss = 1.52031232\n","Iteration 42, loss = 1.56179092\n","Iteration 43, loss = 1.55851163\n","Iteration 44, loss = 1.52588539\n","Iteration 45, loss = 1.51740146\n","Iteration 46, loss = 1.49843719\n","Iteration 47, loss = 1.49647277\n","Iteration 48, loss = 1.50942155\n","Iteration 49, loss = 1.48785512\n","Iteration 50, loss = 1.48578040\n","Iteration 51, loss = 1.48675099\n","Iteration 52, loss = 1.56592854\n","Iteration 53, loss = 1.55567985\n","Iteration 54, loss = 1.54244650\n","Iteration 55, loss = 1.52571979\n","Iteration 56, loss = 1.50591122\n","Iteration 57, loss = 1.49485893\n","Iteration 58, loss = 1.49262360\n","Iteration 59, loss = 1.47236387\n","Iteration 60, loss = 1.45441416\n","Iteration 61, loss = 1.46223280\n","Iteration 62, loss = 1.44945269\n","Iteration 63, loss = 1.45800418\n","Iteration 64, loss = 1.44688574\n","Iteration 65, loss = 1.46874623\n","Iteration 66, loss = 1.47434197\n","Iteration 67, loss = 1.48259611\n","Iteration 68, loss = 1.48914227\n","Iteration 69, loss = 1.43763369\n","Iteration 70, loss = 1.45639143\n","Iteration 71, loss = 1.43474810\n","Iteration 72, loss = 1.45805959\n","Iteration 73, loss = 1.43169246\n","Iteration 74, loss = 1.43088456\n","Iteration 75, loss = 1.48598029\n","Iteration 76, loss = 1.47279013\n","Iteration 77, loss = 1.47648934\n","Iteration 78, loss = 1.44064717\n","Iteration 79, loss = 1.41124940\n","Iteration 80, loss = 1.40958635\n","Iteration 81, loss = 1.41781179\n","Iteration 82, loss = 1.43499339\n","Iteration 83, loss = 1.41161556\n","Iteration 84, loss = 1.40791511\n","Iteration 85, loss = 1.40598064\n","Iteration 86, loss = 1.41801544\n","Iteration 87, loss = 1.40169595\n","Iteration 88, loss = 1.39627105\n","Iteration 89, loss = 1.38636321\n","Iteration 90, loss = 1.41936431\n","Iteration 91, loss = 1.39998766\n","Iteration 92, loss = 1.40671074\n","Iteration 93, loss = 1.41866032\n","Iteration 94, loss = 1.40058012\n","Iteration 95, loss = 1.39559644\n","Iteration 96, loss = 1.43625720\n","Iteration 97, loss = 1.39173040\n","Iteration 98, loss = 1.39797659\n","Iteration 99, loss = 1.37743885\n","Iteration 100, loss = 1.39075595\n","Iteration 101, loss = 1.40182414\n","Iteration 102, loss = 1.41917470\n","Iteration 103, loss = 1.38983691\n","Iteration 104, loss = 1.38218628\n","Iteration 105, loss = 1.37141126\n","Iteration 106, loss = 1.37152263\n","Iteration 107, loss = 1.36017521\n","Iteration 108, loss = 1.37650550\n","Iteration 109, loss = 1.39175780\n","Iteration 110, loss = 1.39635258\n","Iteration 111, loss = 1.40991188\n","Iteration 112, loss = 1.37070709\n","Iteration 113, loss = 1.37057459\n","Iteration 114, loss = 1.35785459\n","Iteration 115, loss = 1.36922136\n","Iteration 116, loss = 1.35729510\n","Iteration 117, loss = 1.34905279\n","Iteration 118, loss = 1.35561121\n","Iteration 119, loss = 1.36824279\n","Iteration 120, loss = 1.41412815\n","Iteration 121, loss = 1.43283614\n","Iteration 122, loss = 1.38554182\n","Iteration 123, loss = 1.39702220\n","Iteration 124, loss = 1.37344714\n","Iteration 125, loss = 1.37029399\n","Iteration 126, loss = 1.38720856\n","Iteration 127, loss = 1.34077557\n","Iteration 128, loss = 1.33497518\n","Iteration 129, loss = 1.35191242\n","Iteration 130, loss = 1.36662343\n","Iteration 131, loss = 1.34224763\n","Iteration 132, loss = 1.35753975\n","Iteration 133, loss = 1.33016003\n","Iteration 134, loss = 1.33885427\n","Iteration 135, loss = 1.33585807\n","Iteration 136, loss = 1.36518181\n","Iteration 137, loss = 1.39304732\n","Iteration 138, loss = 1.43399542\n","Iteration 139, loss = 1.44268130\n","Iteration 140, loss = 1.37142703\n","Iteration 141, loss = 1.35608922\n","Iteration 142, loss = 1.39900104\n","Iteration 143, loss = 1.35624432\n","Iteration 144, loss = 1.34081979\n","Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.94804529\n","Iteration 2, loss = 1.85246987\n","Iteration 3, loss = 1.85360460\n","Iteration 4, loss = 1.83655514\n","Iteration 5, loss = 1.83653019\n","Iteration 6, loss = 1.83629926\n","Iteration 7, loss = 1.83791604\n","Iteration 8, loss = 1.83060400\n","Iteration 9, loss = 1.82987837\n","Iteration 10, loss = 1.83084764\n","Iteration 11, loss = 1.82257783\n","Iteration 12, loss = 1.82827076\n","Iteration 13, loss = 1.81847065\n","Iteration 14, loss = 1.81661364\n","Iteration 15, loss = 1.80800850\n","Iteration 16, loss = 1.79965819\n","Iteration 17, loss = 1.79513745\n","Iteration 18, loss = 1.77657852\n","Iteration 19, loss = 1.77440048\n","Iteration 20, loss = 1.75168337\n","Iteration 21, loss = 1.71391333\n","Iteration 22, loss = 1.70796704\n","Iteration 23, loss = 1.68732928\n","Iteration 24, loss = 1.64533580\n","Iteration 25, loss = 1.62410129\n","Iteration 26, loss = 1.61685555\n","Iteration 27, loss = 1.62849978\n","Iteration 28, loss = 1.57454185\n","Iteration 29, loss = 1.57509084\n","Iteration 30, loss = 1.58634669\n","Iteration 31, loss = 1.54386191\n","Iteration 32, loss = 1.60076221\n","Iteration 33, loss = 1.54331918\n","Iteration 34, loss = 1.55150770\n","Iteration 35, loss = 1.52478171\n","Iteration 36, loss = 1.52760827\n","Iteration 37, loss = 1.55170249\n","Iteration 38, loss = 1.57105784\n","Iteration 39, loss = 1.55092129\n","Iteration 40, loss = 1.51406711\n","Iteration 41, loss = 1.50842490\n","Iteration 42, loss = 1.50956942\n","Iteration 43, loss = 1.51439445\n","Iteration 44, loss = 1.52365293\n","Iteration 45, loss = 1.49180255\n","Iteration 46, loss = 1.50726120\n","Iteration 47, loss = 1.49923208\n","Iteration 48, loss = 1.51494469\n","Iteration 49, loss = 1.48551199\n","Iteration 50, loss = 1.47110220\n","Iteration 51, loss = 1.47900044\n","Iteration 52, loss = 1.46843955\n","Iteration 53, loss = 1.49475116\n","Iteration 54, loss = 1.49606358\n","Iteration 55, loss = 1.46608988\n","Iteration 56, loss = 1.47407628\n","Iteration 57, loss = 1.50594118\n","Iteration 58, loss = 1.48020922\n","Iteration 59, loss = 1.46144718\n","Iteration 60, loss = 1.43722464\n","Iteration 61, loss = 1.44542676\n","Iteration 62, loss = 1.44113528\n","Iteration 63, loss = 1.44889688\n","Iteration 64, loss = 1.44325027\n","Iteration 65, loss = 1.43542931\n","Iteration 66, loss = 1.44662867\n","Iteration 67, loss = 1.44905778\n","Iteration 68, loss = 1.44748660\n","Iteration 69, loss = 1.43681539\n","Iteration 70, loss = 1.41220522\n","Iteration 71, loss = 1.44316554\n","Iteration 72, loss = 1.43659042\n","Iteration 73, loss = 1.42118667\n","Iteration 74, loss = 1.41989664\n","Iteration 75, loss = 1.48326841\n","Iteration 76, loss = 1.51993045\n","Iteration 77, loss = 1.44759205\n","Iteration 78, loss = 1.42045405\n","Iteration 79, loss = 1.39892566\n","Iteration 80, loss = 1.41857589\n","Iteration 81, loss = 1.41363119\n","Iteration 82, loss = 1.40451748\n","Iteration 83, loss = 1.43107852\n","Iteration 84, loss = 1.42283804\n","Iteration 85, loss = 1.43862651\n","Iteration 86, loss = 1.42086874\n","Iteration 87, loss = 1.39925546\n","Iteration 88, loss = 1.39951742\n","Iteration 89, loss = 1.39906016\n","Iteration 90, loss = 1.38545973\n","Iteration 91, loss = 1.37220847\n","Iteration 92, loss = 1.38586673\n","Iteration 93, loss = 1.37592336\n","Iteration 94, loss = 1.38178100\n","Iteration 95, loss = 1.41014717\n","Iteration 96, loss = 1.40688946\n","Iteration 97, loss = 1.41582294\n","Iteration 98, loss = 1.41712712\n","Iteration 99, loss = 1.38999247\n","Iteration 100, loss = 1.38240499\n","Iteration 101, loss = 1.37065368\n","Iteration 102, loss = 1.38367723\n","Iteration 103, loss = 1.41598379\n","Iteration 104, loss = 1.43013647\n","Iteration 105, loss = 1.42389817\n","Iteration 106, loss = 1.43800601\n","Iteration 107, loss = 1.38803274\n","Iteration 108, loss = 1.37778039\n","Iteration 109, loss = 1.36086009\n","Iteration 110, loss = 1.37784228\n","Iteration 111, loss = 1.35850644\n","Iteration 112, loss = 1.35715829\n","Iteration 113, loss = 1.35982120\n","Iteration 114, loss = 1.35571309\n","Iteration 115, loss = 1.47074833\n","Iteration 116, loss = 1.49895585\n","Iteration 117, loss = 1.44157749\n","Iteration 118, loss = 1.42599038\n","Iteration 119, loss = 1.35623192\n","Iteration 120, loss = 1.33613189\n","Iteration 121, loss = 1.35250524\n","Iteration 122, loss = 1.33169446\n","Iteration 123, loss = 1.34610992\n","Iteration 124, loss = 1.34106329\n","Iteration 125, loss = 1.33754379\n","Iteration 126, loss = 1.34093340\n","Iteration 127, loss = 1.32545928\n","Iteration 128, loss = 1.38507931\n","Iteration 129, loss = 1.37832716\n","Iteration 130, loss = 1.34601488\n","Iteration 131, loss = 1.35455571\n","Iteration 132, loss = 1.34016804\n","Iteration 133, loss = 1.33223018\n","Iteration 134, loss = 1.34557811\n","Iteration 135, loss = 1.33627305\n","Iteration 136, loss = 1.33023015\n","Iteration 137, loss = 1.34446977\n","Iteration 138, loss = 1.33514631\n","Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 1.94788101\n","Iteration 2, loss = 1.85209841\n","Iteration 3, loss = 1.84862537\n","Iteration 4, loss = 1.84233298\n","Iteration 5, loss = 1.83811558\n","Iteration 6, loss = 1.83444013\n","Iteration 7, loss = 1.83509565\n","Iteration 8, loss = 1.83250487\n","Iteration 9, loss = 1.83069970\n","Iteration 10, loss = 1.82544862\n","Iteration 11, loss = 1.82333151\n","Iteration 12, loss = 1.82021096\n","Iteration 13, loss = 1.81569901\n","Iteration 14, loss = 1.81165849\n","Iteration 15, loss = 1.81299345\n","Iteration 16, loss = 1.82036926\n","Iteration 17, loss = 1.80147727\n","Iteration 18, loss = 1.78427469\n","Iteration 19, loss = 1.76973011\n","Iteration 20, loss = 1.76265365\n","Iteration 21, loss = 1.74394802\n","Iteration 22, loss = 1.72267269\n","Iteration 23, loss = 1.69581261\n","Iteration 24, loss = 1.66313457\n","Iteration 25, loss = 1.63384495\n","Iteration 26, loss = 1.59741950\n","Iteration 27, loss = 1.64431452\n","Iteration 28, loss = 1.69839505\n","Iteration 29, loss = 1.63369860\n","Iteration 30, loss = 1.57527461\n","Iteration 31, loss = 1.54926257\n","Iteration 32, loss = 1.53479813\n","Iteration 33, loss = 1.55708686\n","Iteration 34, loss = 1.56702985\n","Iteration 35, loss = 1.53300358\n","Iteration 36, loss = 1.52793881\n","Iteration 37, loss = 1.52495208\n","Iteration 38, loss = 1.50428855\n","Iteration 39, loss = 1.50164016\n","Iteration 40, loss = 1.50597883\n","Iteration 41, loss = 1.50796977\n","Iteration 42, loss = 1.48749852\n","Iteration 43, loss = 1.48234708\n","Iteration 44, loss = 1.46868954\n","Iteration 45, loss = 1.51945266\n","Iteration 46, loss = 1.47919465\n","Iteration 47, loss = 1.54268829\n","Iteration 48, loss = 1.52740526\n","Iteration 49, loss = 1.49861723\n","Iteration 50, loss = 1.46603840\n","Iteration 51, loss = 1.47130114\n","Iteration 52, loss = 1.43940555\n","Iteration 53, loss = 1.45489814\n","Iteration 54, loss = 1.46429438\n","Iteration 55, loss = 1.46772361\n","Iteration 56, loss = 1.45572872\n","Iteration 57, loss = 1.43853307\n","Iteration 58, loss = 1.46064717\n","Iteration 59, loss = 1.49861020\n","Iteration 60, loss = 1.47995410\n","Iteration 61, loss = 1.45095671\n","Iteration 62, loss = 1.45336404\n","Iteration 63, loss = 1.45489875\n","Iteration 64, loss = 1.43000179\n","Iteration 65, loss = 1.42713835\n","Iteration 66, loss = 1.41856807\n","Iteration 67, loss = 1.40810025\n","Iteration 68, loss = 1.41227241\n","Iteration 69, loss = 1.41629514\n","Iteration 70, loss = 1.42199981\n","Iteration 71, loss = 1.41747849\n","Iteration 72, loss = 1.40657042\n","Iteration 73, loss = 1.40484035\n","Iteration 74, loss = 1.42454284\n","Iteration 75, loss = 1.44802053\n","Iteration 76, loss = 1.40870326\n","Iteration 77, loss = 1.41391052\n","Iteration 78, loss = 1.43296288\n","Iteration 79, loss = 1.41114944\n","Iteration 80, loss = 1.44959206\n","Iteration 81, loss = 1.39889020\n","Iteration 82, loss = 1.38807383\n","Iteration 83, loss = 1.37953013\n","Iteration 84, loss = 1.38548241\n","Iteration 85, loss = 1.40208330\n","Iteration 86, loss = 1.39068762\n","Iteration 87, loss = 1.39765457\n","Iteration 88, loss = 1.38530907\n","Iteration 89, loss = 1.38989531\n","Iteration 90, loss = 1.42224294\n","Iteration 91, loss = 1.47302724\n","Iteration 92, loss = 1.40016270\n","Iteration 93, loss = 1.41886806\n","Iteration 94, loss = 1.43753104\n","Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n","Log loss : 1.2716916496427304\n","Actual : 1\n","Probability : [[0.2015 0.1111 0.0277 0.2483 0.0584 0.0568 0.2476 0.0195 0.0292]]\n","Predicted : [4]\n","[[ 31   1   0  59   6   4  13   0   0]\n"," [  5  20   0   2   0   0  64   0   0]\n"," [  1   1   0   4   3   0   9   0   0]\n"," [ 29   0   0  86   5   1  16   0   0]\n"," [  5   0   0   6  20   6  11   0   0]\n"," [ 12   4   0   6   4  17  12   0   0]\n"," [  3   9   0   3   0   0 176   0   0]\n"," [  1   0   0   0   0   0   3   0   0]\n"," [  2   0   0   3   0   0   2   0   0]]\n","Score : 0.5263157894736842\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p1OW1bziUlyz","colab_type":"text"},"source":["## Ensemble Model Extra Tree Classifier"]},{"cell_type":"code","metadata":{"id":"hq0UBTx99wb3","colab_type":"code","outputId":"fa946ba9-74a8-42f0-9666-d44474e687aa","executionInfo":{"status":"ok","timestamp":1554996474096,"user_tz":-330,"elapsed":166649,"user":{"displayName":"Atul Rana","photoUrl":"https://lh4.googleusercontent.com/-tLVUUtH-AZE/AAAAAAAAAAI/AAAAAAAAMt0/14Rk9-FZ5I4/s64/photo.jpg","userId":"06185900944594624481"}},"colab":{"base_uri":"https://localhost:8080/","height":315}},"source":["from sklearn.ensemble.forest import ExtraTreesClassifier\n","clf = ExtraTreesClassifier( n_estimators= 1000,  max_features= None,bootstrap=True, oob_score= True, class_weight='balanced', n_jobs= -1) \n","predict_and_plot_confusion_matrix(mean_embedded, y, clf)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n","  warnings.warn(CV_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Log loss : 0.9938384726993784\n","Actual : 1\n","Probability : [[0.3842 0.0615 0.0183 0.1592 0.237  0.0778 0.0518 0.005  0.0053]]\n","Predicted : [1]\n","[[ 69   2   1  18   9   4  11   0   0]\n"," [  4  43   0   1   0   1  42   0   0]\n"," [  1   0   7   3   0   0   7   0   0]\n"," [ 23   3   1 100   1   2   6   0   1]\n"," [ 13   2   1   6  19   3   4   0   0]\n"," [  5   0   0   2   0  39   9   0   0]\n"," [  4  11   3   3   2   0 168   0   0]\n"," [  0   0   0   0   0   0   2   1   1]\n"," [  1   0   0   0   0   0   0   1   5]]\n","Score : 0.6781954887218045\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wu_qYrP2AHFC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}